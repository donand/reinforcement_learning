{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\n",
    "# Markov Property\n",
    "The probability of a state depends only on the last previous state (First-order markov assumption). For the second order, the last two states.<br>\n",
    "We can define the problem in a way such that the markov assumption is not limiting.<br>\n",
    "In reinforcement learning in particular, the assumption becomes:\n",
    "\n",
    "$$p(s', r | s, a) = p(S_{t+1} = s', R_{t+1} = r | S_t = s, A_t = a)$$\n",
    "\n",
    "The MDP is defined by five elements:\n",
    "- Set of states\n",
    "- Set of actions\n",
    "- Set of rewards\n",
    "- State-transition probabilities, reward probabilities\n",
    "- Discount factor\n",
    "\n",
    "The policy $\\pi$ is the \"algorithm\" of the solution.\n",
    "The state transition can be stochastic, if for example the agent can sense only a small parte of the environment (e.g. blackjack)\n",
    "\n",
    "# Value Function\n",
    "The value function, given a policy and the state s, is equal to the expected value of the return given that you are currently in the state s.<br>\n",
    "- State Value function: $$V_{\\pi}(s) = E_{\\pi}[G(t) | S_t = s]$$<br>\n",
    "- Action value function: $$Q_{\\pi}(s, a) = E_{\\pi}[G(t) | S_t = s, A_t = a]$$\n",
    "\n",
    "# Optimal Policy\n",
    "We can have several optimal policies that lead to the same value function, but only one optimal value function.<br>\n",
    "The optimal state-value function is the maximum action-value function over all actions.<br>\n",
    "\n",
    "$$V_*(s) = \\max_a{Q_*(s, a)}$$\n",
    "\n",
    "If we have V(s), in the state s we have to try all the possible actions to find the action that lead to the best V(s'). With Q(s, a) instead, we just choose the action with the maximum value.<br>\n",
    "The value functions already take into account the future rewards."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
